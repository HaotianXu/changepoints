---
title: "HD_regression"
author: "Haotian Xu"
date: "9/2/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is a simple guide for changepoint detection in high-dimensional linear regression.

Function _simu.change.regression_ simulates sparse regression model with changepoints in coefficients.

Dynamic programming is implemented for regression changepoint detection:

* _DP.regression_: performs dynamic programming for regression changepoint detection through l0 penalty.
   + _CV.search.DP.regression_: perform grid search to select the tuning parameters (gamma for l0, lambda for l1) through Cross-Validation.

In addition, function _local.refine.regression_ performs local refinement for an initial changepoint estimation.

# Simulate data
```{r}
library(changepoints)
## parameters for simulating data
d0 = 5 # the number of nonzero elements
sigma = 1 # error standard deviation
kappa = 5 # minimum jump size in l2 norm
delta = 5 # minimal gap between boundaries
n = 200 # sample size
p = 50 # dimensionality
change.point = c(80, 170)

set.seed(0)
data = simu.change.regression(d0, change.point, p, n, sigma, kappa)
X = data$X
y = data$y
cpt_true = data$cpt.true
```

# Perform dynamic programming
```{r}
gamma.dp.set = c(0.01, 0.5, 1, 5, 10, 50) # a set of tuning parameters for DP
lambda.dp.set = c(0.01, 0.1, 1, 1.5) # a set of tuning parameters for lasso
DP_result = CV.search.DP.regression(y, X, gamma.dp.set, lambda.dp.set, delta) # grid search through cross-validation
min_idx = as.vector(arrayInd(which.min(DP_result$test_error), dim(DP_result$test_error)))# select gamma achieves the minimum validation error
cpt_DP_hat = unlist(DP_result$cpt_hat[min_idx[1], min_idx[2]]) # estimated changepoints by DP
cpt_DP_hat
Hausdorff.dist(cpt_DP_hat, cpt_true)
zeta = 1 # tuning parameter for group lasso
cpt_DPlr_hat = local.refine.regression(cpt_DP_hat, y, X, zeta, w = 1/3) # perform local refinement
cpt_DPlr_hat
Hausdorff.dist(cpt_DPlr_hat, cpt_true)
```